{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyr5211-pZx0"
      },
      "source": [
        "# **SUMMARIX: Our Project allows a User to upload a video and get a transcript and a Summary of its content**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLVM8_dkpoiA"
      },
      "source": [
        "## **Installing required packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Ola9Zw1zQC",
        "outputId": "bbaf699d-85d2-4460-9ef2-e71360cde96a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yt-dlp\n",
            "  Using cached yt_dlp-2025.3.31-py3-none-any.whl.metadata (172 kB)\n",
            "Collecting moviepy\n",
            "  Downloading moviepy-2.1.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting openai-whisper\n",
            "  Using cached openai-whisper-20240930.tar.gz (800 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: decorator<6.0,>=4.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from moviepy) (5.1.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from moviepy) (2.33.1)\n",
            "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
            "  Downloading imageio_ffmpeg-0.6.0-py3-none-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from moviepy) (1.26.4)\n",
            "Collecting proglog<=1.0.0 (from moviepy)\n",
            "  Downloading proglog-0.1.11-py3-none-any.whl.metadata (794 bytes)\n",
            "Requirement already satisfied: python-dotenv>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from moviepy) (0.21.0)\n",
            "Requirement already satisfied: pillow<11.0,>=9.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from moviepy) (10.4.0)\n",
            "Requirement already satisfied: numba in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (0.60.0)\n",
            "Collecting torch (from openai-whisper)\n",
            "  Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->openai-whisper) (75.1.0)\n",
            "Collecting sympy==1.13.1 (from torch->openai-whisper)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Downloading yt_dlp-2025.3.31-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading moviepy-2.1.2-py3-none-any.whl (126 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "Downloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
            "Downloading imageio_ffmpeg-0.6.0-py3-none-macosx_11_0_arm64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading proglog-0.1.11-py3-none-any.whl (7.8 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=aad9869f744e36e7670d4a182c28c60f208f8f79a7976da331db7a79e39bbfa1\n",
            "  Stored in directory: /Users/yashasyadav/Library/Caches/pip/wheels/7c/f5/6f/92094c35416f9397abb86b23cfe72fb255a3013012f983136d\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: pydub, yt-dlp, sympy, safetensors, pytube, proglog, imageio_ffmpeg, torch, tiktoken, moviepy, huggingface-hub, tokenizers, openai-whisper, transformers\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.2\n",
            "    Uninstalling sympy-1.13.2:\n",
            "      Successfully uninstalled sympy-1.13.2\n",
            "Successfully installed huggingface-hub-0.30.1 imageio_ffmpeg-0.6.0 moviepy-2.1.2 openai-whisper-20240930 proglog-0.1.11 pydub-0.25.1 pytube-15.0.0 safetensors-0.5.3 sympy-1.13.1 tiktoken-0.9.0 tokenizers-0.21.1 torch-2.6.0 transformers-4.50.3 yt-dlp-2025.3.31\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp moviepy pydub openai-whisper transformers pytube"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS_dnNMrp_nn"
      },
      "source": [
        "## **Importing the necessary libraries and defining file paths and directories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NwND2GRqCgM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import yt_dlp\n",
        "import whisper\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from moviepy.editor import VideoFileClip\n",
        "from google.colab import files\n",
        "\n",
        "# Define file paths and directories\n",
        "VIDEO_FILE = \"video.mp4\"\n",
        "AUDIO_FILE = \"audio.mp3\"\n",
        "FRAMES_DIR = \"frames\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSZneLz0qSy7"
      },
      "source": [
        "## **Function to extract audio from video**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E_xhH61aqYAB"
      },
      "outputs": [],
      "source": [
        "def extract_audio_from_video(video_path):\n",
        "    print(\"Extracting audio from video...\")\n",
        "    video = VideoFileClip(video_path)\n",
        "    temp_audio_path = tempfile.mktemp(suffix='.wav')\n",
        "    video.audio.write_audiofile(temp_audio_path, codec='pcm_s16le')\n",
        "    video.close()\n",
        "    return temp_audio_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQTpn9-Kqwzz"
      },
      "source": [
        "## **Function to Transcribe audio using Whisper**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "23kmuIODq2CJ"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(audio_path):\n",
        "    print(\"Transcribing audio... (this may take a while depending on video length)\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptzp-cROrBgw"
      },
      "source": [
        "## **Function to summarize text using BART**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lVC0QFZ8rIr3"
      },
      "outputs": [],
      "source": [
        "def summarize_text(text, max_length=500, min_length=100):\n",
        "    print(\"Generating summary...\")\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    max_chunk_size = 1024\n",
        "    chunks = [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        if len(chunk) > 100:\n",
        "            result = summarizer(chunk, max_length=max_length // len(chunks), min_length=min_length // len(chunks))\n",
        "            summaries.append(result[0]['summary_text'])\n",
        "    return \" \".join(summaries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srO3qj4uuaLl"
      },
      "source": [
        "## **Function to process video: extract audio, transcribe, and summarize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EaksRHPDukCT"
      },
      "outputs": [],
      "source": [
        "def process_video(video_path):\n",
        "    audio_path = extract_audio_from_video(video_path)\n",
        "    transcript = transcribe_audio(audio_path)\n",
        "    os.remove(audio_path)\n",
        "    print(\"\\n===== FULL TRANSCRIPT =====\")\n",
        "    print(transcript)\n",
        "    summary = summarize_text(transcript)\n",
        "    print(\"\\n===== VIDEO SUMMARY =====\")\n",
        "    print(summary)\n",
        "    return transcript, summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpHLpb4Qu0xK"
      },
      "source": [
        "## **Function to download and process a YouTube video using yt-dlp**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5E-5RlKau7Pd"
      },
      "outputs": [],
      "source": [
        "def process_youtube_video(youtube_url):\n",
        "    print(\"Downloading YouTube video...\")\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    ydl_opts = {\n",
        "        'outtmpl': os.path.join(temp_dir, '%(id)s.%(ext)s'),\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',\n",
        "        'merge_output_format': 'mp4',\n",
        "        'cookiefile': 'cookies.txt',\n",
        "        'verbose': True,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(youtube_url, download=True)\n",
        "            video_path = ydl.prepare_filename(info)\n",
        "            transcript, summary = process_video(video_path)\n",
        "            os.remove(video_path)\n",
        "            os.rmdir(temp_dir)\n",
        "            return transcript, summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing YouTube video: {e}\")\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS7QfHe_vBYL"
      },
      "source": [
        "## **User Interface for video processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pVk-lQ25vTtn",
        "outputId": "010c7a07-7c0d-4eff-cf66-c2ca63eec254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== VIDEO SUMMARIZER =====\n",
            "Please choose an option:\n",
            "1. Upload a video file\n",
            "2. Use a YouTube URL\n",
            "Enter your choice (1 or 2): 2\n",
            "Enter the YouTube URL: https://www.youtube.com/watch?v=K27diMbCsuw&t=126s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2025.02.19 from yt-dlp/yt-dlp [4985a4041] (pip) API\n",
            "[debug] params: {'outtmpl': '/tmp/tmp7h7h8jlz/%(id)s.%(ext)s', 'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]', 'merge_output_format': 'mp4', 'cookiefile': 'cookies.txt', 'verbose': True, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.54 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}}\n",
            "[debug] Python 3.11.11 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: certifi-2025.01.31, requests-2.32.3, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.3.0, websockets-14.2\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1841 extractors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading YouTube video...\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=K27diMbCsuw&t=126s\n",
            "[youtube] K27diMbCsuw: Downloading webpage\n",
            "[youtube] K27diMbCsuw: Downloading tv client config\n",
            "[youtube] K27diMbCsuw: Downloading player 74e4bb46\n",
            "[youtube] K27diMbCsuw: Downloading tv player API JSON\n",
            "[youtube] K27diMbCsuw: Downloading ios player API JSON\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[debug] [youtube] Extracting signature function js_74e4bb46_102\n",
            "[debug] Loading youtube-sigfuncs.js_74e4bb46_102 from cache\n",
            "[debug] Loading youtube-nsig.74e4bb46 from cache\n",
            "[debug] [youtube] Decrypted nsig rOSB8Sf4y1gpaR7zM6d => DANnCZtFfPBRnA\n",
            "[debug] [youtube] Extracting signature function js_74e4bb46_106\n",
            "[debug] Loading youtube-sigfuncs.js_74e4bb46_106 from cache\n",
            "[debug] Loading youtube-nsig.74e4bb46 from cache\n",
            "[debug] [youtube] Decrypted nsig 527GrVWL93xHHriiXIA => 675HQ87CGbLcvQ\n",
            "[debug] [youtube] K27diMbCsuw: ios client https formats require a GVS PO Token which was not provided. They will be skipped as they may yield HTTP Error 403. You can manually pass a GVS PO Token for this client with --extractor-args \"youtube:po_token=ios.gvs+XXX\". For more information, refer to  https://github.com/yt-dlp/yt-dlp/wiki/PO-Token-Guide . To enable these broken formats anyway, pass --extractor-args \"youtube:formats=missing_pot\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] K27diMbCsuw: Downloading m3u8 information\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec, channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] K27diMbCsuw: Downloading 1 format(s): 401+140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[debug] Invoking http downloader on \"https://rr4---sn-qxo7rn7k.googlevideo.com/videoplayback?expire=1741862099&ei=c2DSZ-HWD8zcybgP0Jr4qAw&ip=34.28.238.135&id=o-AKvMlwAGvV_GwmDz8jf8d5cANXLL2TyreglEXDU79a1J&itag=401&aitags=133%2C134%2C135%2C136%2C160%2C242%2C243%2C244%2C247%2C278%2C298%2C299%2C302%2C303%2C308%2C315%2C394%2C395%2C396%2C397%2C398%2C399%2C400%2C401&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1741840499%2C&mh=cA&mm=31%2C26&mn=sn-qxo7rn7k%2Csn-a5mlrnlz&ms=au%2Conr&mv=m&mvi=4&pl=16&rms=au%2Cau&initcwndbps=9918750&bui=AUWDL3yGJ5_7ew6l6TPWtl1mtNcwLFJ8G8eXrYKHX_rHgcT9D2MhraSzRzzrSqKyAQWfaEIlQH9W6h_8&vprv=1&svpuc=1&mime=video%2Fmp4&ns=wZT7eIcSyIs5iov6UsIXae4Q&rqh=1&gir=yes&clen=120012187&dur=257.799&lmt=1741453808560980&mt=1741840125&fvip=5&keepalive=yes&lmw=1&fexp=51358317%2C51411872&c=TVHTML5&sefc=1&txp=5532534&n=675HQ87CGbLcvQ&sparams=expire%2Cei%2Cip%2Cid%2Caitags%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AFVRHeAwRQIhAM1JkXDl58iZ1CvY1XpqkhC82C_aj-UG24vsILy5Fkf-AiBeaAM5YpbIIxWFv6nGzoIMYBwO5ZxnnkPIsF0JzfhO3A%3D%3D&sig=AJfQdSswRQIgT9m8dnDcaYFBjDN1s7nnFQaOgHeLP13mm9A44XPu5LUCIQD3FE6eXmnbRYDo7r5seBwvocqPbKy0-i6iCJkz__88hg%3D%3D\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[download] Destination: /tmp/tmp7h7h8jlz/K27diMbCsuw.f401.mp4\n",
            "[download] 100% of  114.45MiB in 00:00:02 at 43.76MiB/s  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[debug] Invoking http downloader on \"https://rr4---sn-qxo7rn7k.googlevideo.com/videoplayback?expire=1741862099&ei=c2DSZ-HWD8zcybgP0Jr4qAw&ip=34.28.238.135&id=o-AKvMlwAGvV_GwmDz8jf8d5cANXLL2TyreglEXDU79a1J&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1741840499%2C&mh=cA&mm=31%2C26&mn=sn-qxo7rn7k%2Csn-a5mlrnlz&ms=au%2Conr&mv=m&mvi=4&pl=16&rms=au%2Cau&initcwndbps=9918750&bui=AUWDL3yGJ5_7ew6l6TPWtl1mtNcwLFJ8G8eXrYKHX_rHgcT9D2MhraSzRzzrSqKyAQWfaEIlQH9W6h_8&vprv=1&svpuc=1&mime=audio%2Fmp4&ns=wZT7eIcSyIs5iov6UsIXae4Q&rqh=1&gir=yes&clen=4175039&dur=257.927&lmt=1741448326473558&mt=1741840125&fvip=5&keepalive=yes&lmw=1&fexp=51358317%2C51411872&c=TVHTML5&sefc=1&txp=5532534&n=675HQ87CGbLcvQ&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AFVRHeAwRQIhAM1JkXDl58iZ1CvY1XpqkhC82C_aj-UG24vsILy5Fkf-AiBeaAM5YpbIIxWFv6nGzoIMYBwO5ZxnnkPIsF0JzfhO3A%3D%3D&sig=AJfQdSswRAIgfb3mJjhnW_0XIp9GpDFFBuTgbWdIrzyOXekzZemEou8CIAGwnKCiFMpihxPli-qAuKREsOQAue9MmGSo7XJ243Vv\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[download] Destination: /tmp/tmp7h7h8jlz/K27diMbCsuw.f140.m4a\n",
            "[download] 100% of    3.98MiB in 00:00:00 at 37.38MiB/s  \n",
            "[Merger] Merging formats into \"/tmp/tmp7h7h8jlz/K27diMbCsuw.mp4\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i file:/tmp/tmp7h7h8jlz/K27diMbCsuw.f401.mp4 -i file:/tmp/tmp7h7h8jlz/K27diMbCsuw.f140.m4a -c copy -map 0:v:0 -map 1:a:0 -movflags +faststart file:/tmp/tmp7h7h8jlz/K27diMbCsuw.temp.mp4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleting original file /tmp/tmp7h7h8jlz/K27diMbCsuw.f140.m4a (pass -k to keep)\n",
            "Deleting original file /tmp/tmp7h7h8jlz/K27diMbCsuw.f401.mp4 (pass -k to keep)\n",
            "Extracting audio from video...\n",
            "MoviePy - Writing audio in /tmp/tmp2ar36gjx.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Transcribing audio... (this may take a while depending on video length)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== FULL TRANSCRIPT =====\n",
            " Hi, I'm Pete from Manus AI. For the past year, we'll be quietly building what we believe is the next evolution in AI. And today, we're launching an early preview of Manus, the first general AI agent. This isn't just another chap-out of workflow. It's a truly autonomous agent that bridges the gap between conception and execution, what other AI stops at generating ideas, Manus delivers results. We see it as the next paradigm of human machine collaboration, and potentially, it glims into AI. Now, let me show you Manus in action across three completely different tasks. Let's start with an easy one. In this example, we ask Manus to help screen resumes. I've just said Manus is if file containing 10 resume documents. Since each Manus agent has its own computer, it can work like a human. First, I'm zipping the file, then browsing through each resume page by page, and recording important information to documents. Manus works asynchronously in the file, which means you can close your laptop anytime, and Manus will notify you when everything is complete. Of course, you can also give Manus new instructors at any time. Here, I've sent Manus five more resumes. After carefully reading all 15 resumes, Manus provides a ranking such as since, along with the candidate profiles and evaluation criteria as supporting materials. This is pretty good, but I prefer a spreadsheet. Let's have Manus create one. Manus has his own knowledge of memory, so it can teach Manus that the next time it handles a similar task, it will deliver a spreadsheet right away. In this example, we have Manus conducts in research. It needs to filter a new York property based on multiple criteria. For complex tasks, Manus first creeps down and creates a to-do list. Manus begins by searching and carefully reading articles about the safest neighborhoods. Then Manus research his middle schools in New York. Next, Manus writes a Python program to calculate my budget. Based on my budget, Manus filters listings on real estate websites. Finally, combining all the information gathered, Manus writes a detailed report and compiles all the resources. In this example, we have Manus perform a correlation analysis between stocks. For professional data, Manus can access authoritative data sources through APIs. After validating the required data, Manus begins writing code for data analysis and visualization. For Manus, coding isn't necessary to the goal, but rather a universal tool for solving problems. It looks like Manus has completed the data analysis and visualization. But interactive data visualization is even cooler, so I asked Manus to create a website based on these data. With my permission, Manus deploys the finished website online and provides me with a shareable link. Let's see what Manus has created. What you've just seen is just a small sample of what Manus can do. In fact, on benchmarks designed to evaluate general AI assistance, an early checkpoint of Manus has already achieved state-of-the-art performance and is only getting better. Beyond benchmarks, Manus has been solving real-world problems on platforms like Upwork and Fiverr and has proven its capabilities on Kaggle competitions. This wouldn't be possible without the amazing open source community, which is why we're committed to giving back. Manus operates as a multi-agent system powered by several distinct models. So later this year, we're going to open source some of these models, specifically post-trained for Manus, inviting everyone to explore this eGentic future together. The name Manus comes from the famous model, Men's at Manus, Mind and Hand. It embodies the belief that knowledge must be applied to make a meaningful impact on the world. And this is precisely the promise of Manus AI. To extend your capabilities, amplify your impact, and be the hand that brings your mind's vision into reality. We can't wait to see what you will achieve with Manus.\n",
            "Generating summary...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== VIDEO SUMMARY =====\n",
            "Manus is the first general AI agent. It's a truly autonomous agent that bridges the gap between conception and execution. We see it as the next paradigm of human machine collaboration. For complex tasks, Manus first creeps down and creates a to-do list. Manus has his own knowledge of memory, so it can teach Manus that the next time it handles a similar task, it will deliver a spreadsheet. Manus can access authoritative data sources through APIs. After validating the required data, Manus begins writing code for data analysis and visualization. For Manus, coding isn't necessary to the goal, but rather a universal tool. Manus operates as a multi-agent system powered by several distinct models. Later this year, we're going to open source some of these models, specifically post-trained for Manus.\n",
            "\n",
            "Transcript and summary have been saved to text files.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4b4d1479-f6e3-46ed-a4a9-96f25d2d3883\", \"transcript.txt\", 3928)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_376458fa-72ed-4dfa-9105-d4a7ad9cc3bf\", \"summary.txt\", 802)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"===== VIDEO SUMMARIZER =====\")\n",
        "print(\"Please choose an option:\")\n",
        "print(\"1. Upload a video file\")\n",
        "print(\"2. Use a YouTube URL\")\n",
        "option = input(\"Enter your choice (1 or 2): \")\n",
        "\n",
        "if option == \"1\":\n",
        "    print(\"Upload your video file:\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Processing {filename}...\")\n",
        "        transcript, summary = process_video(filename)\n",
        "        with open(\"transcript.txt\", \"w\") as f:\n",
        "            f.write(transcript)\n",
        "        with open(\"summary.txt\", \"w\") as f:\n",
        "            f.write(summary)\n",
        "        print(\"\\nTranscript and summary have been saved to text files.\")\n",
        "        files.download(\"transcript.txt\")\n",
        "        files.download(\"summary.txt\")\n",
        "elif option == \"2\":\n",
        "    youtube_url = input(\"Enter the YouTube URL: \")\n",
        "    transcript, summary = process_youtube_video(youtube_url)\n",
        "    if transcript:\n",
        "        with open(\"transcript.txt\", \"w\") as f:\n",
        "            f.write(transcript)\n",
        "        with open(\"summary.txt\", \"w\") as f:\n",
        "            f.write(summary)\n",
        "        print(\"\\nTranscript and summary have been saved to text files.\")\n",
        "        files.download(\"transcript.txt\")\n",
        "        files.download(\"summary.txt\")\n",
        "else:\n",
        "    print(\"Invalid option selected.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
